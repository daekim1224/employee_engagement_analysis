---
title: "employee_engagement_analysis"
author: "Daehyeon (Dae) Kim"
date: "2024-04-15"
output: html_document : github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Overview of This Report
Purpose: This report shows my data analysis of Hooli's employee enagement.

This report is structured as follows: 

* Data preparation

 - Loading Data
```{r}
library(readxl)
df_original <- read_xlsx("data/Sr._People_Science_Analyst_Assignment_Dataset.xlsx")
```
 - Exaimining the loaded data at the macro-level
  
    -'lea_3' should be a numeric variable. After checking the data, employee ID M01562's response is only missing for 'lea_3'. Therefore, this 'N/A' should be recoded as -1. 
  
    - hiredate should be a date variable. But it is important to note that the current format is written as day/month/year. So I need to specify this in my code. 

```{r}
head(df_original)
tail(df_original)

str(df_original)

df <- df_original

table(df_original$lea_3)
df[df$lea_3 == "N/A", ]
df$lea_3[df$lea_3 == "N/A"] <- -1
table(df$lea_3)
df$lea_3 <- as.numeric(df$lea_3)

df$hiredate <- as.Date(df$hiredate, format = "%d/%m/%Y")
str(df)

```


  - Data pre-processing
    
- The presence of outliers, max value 99 for ali_1, ali_2, ali_3, col_1, col_2, col_3, lea_4. The value 99 is a value that is out of scale of -1 to 5. I discovered that all these responses come from Denmark. There seems to be a sampling error or coding error for responses from Denmark. Given that these are psychological measures, after going through the data dictionary, it doesn't make sense code 99 might denote an exceptional response out of -1 to 5 scale. Thus, I deem 99 as a coding error. Given that these employees are less than 1% of the population and that they completed the survey, I recode 99 to -1, the code for missing value. 
    
```{r}
library(summarytools)
dfSummary(df)

#examine the responses of the employees who responsed 99 to one of these questions.
df[df$ali_1 == 99, ] # other responses are in the normal scale range, 2 participants = M00238 & M00568
df[df$ali_2 == 99, ] # except for ali_2 & lea_4, all the other responses are in the normal scale range, 1 participant = M01455
df[df$ali_3 == 99, ] # other responses are in the normal scale range, 1 participant = M02319
df[df$col_1 == 99, ] # other responses are in the normal scale range, 2 participants = M01339, M01843
df[df$col_2 == 99, ] # other responses are in the normal scale range, 1 participant = M00168
df[df$col_3 == 99, ] # other responses are in the normal scale range, 1 participant = M01393
df[df$lea_3 == 99, ] # except fo lea_3, all the other responses are in the normal scale range, 1 participant = M01484
df[df$lea_4 == 99, ] # except for ali_2 & lea_4, all the other responses are in the normal scale range, 1 participant = M01455

# recode values with 99 to -1.

df$ali_1[df$ali_1 == 99] <- -1
df$ali_2[df$ali_2 == 99] <- -1
df$ali_3[df$ali_3 == 99] <- -1
df$col_1[df$col_1 == 99] <- -1
df$col_2[df$col_2 == 99] <- -1
df$col_3[df$col_3 == 99] <- -1
df$lea_3[df$lea_3 == 99] <- -1
df$lea_4[df$lea_4 == 99] <- -1

dfSummary(df)

```
 - col_1, eng_2, inc_2, & inc_5 have 1 missing value each. It should be correctly coded as -1. 
```{r}
df[is.na(df$col_1), ] #for employee_ID M02429, only col_1 is missing. It should be coded as -1. 
df[is.na(df$eng_2), ] #for employee_ID M01597, only eng_2 is missing. It should be coded as -1.
df[is.na(df$inc_2), ] #for employee_ID M01481, only inc_2 is missing. It should be coded as -1.
df[is.na(df$inc_5), ] #for employee_ID M01722, only inc_5 is missing. It should be coded as -1. 

df$col_1[is.na(df$col_1)] <- -1
df$eng_2[is.na(df$eng_2)] <- -1
df$inc_2[is.na(df$inc_2)] <- -1
df$inc_5[is.na(df$inc_5)] <- -1

```
        - duplicates: there are no duplicates based on employee ID
```{r}
sum(duplicated(df$eeid))
```
  
 - for 'country' variable, UK & United Kingdom should be the same category. Similarly, USA & United States should be the same category. Let's collapse these categories together for each country. 
```{r}

table(df$country)
df$country[df$country == "UK"] <- "United Kingdom"
df$country[df$country == "USA"] <- "United States"
table(df$country)

```
- age:  
        - the group '19', '21' should be consolidated into '18-24'.
        - the group '26', '28' should be consolidated into '25-34'.
        - the group '39', '42' should be consolidated into '35-44'.
        - the group '48' should be consolidated into '45-54'.
```{r}
table(df$age, useNA = "always")

df$age[df$age == "19"] <- "18-24"
df$age[df$age == "21"] <- "18-24"
df$age[df$age == "26"] <- "25-34"
df$age[df$age == "28"] <- "25-34"
df$age[df$age == "39"] <- "35-44"
df$age[df$age == "42"] <- "35-44"
df$age[df$age == "48"] <- "45-54"


```
- race: 
          -Consolidate "Black or African American" & "Black or African Americans" into one group.
```{r}
table(df$race, useNA = "always")
df$race[df$race == "Black or African Americans"] <- "Black or African American"
```
- gender:
            -Consolidate "Male" & "Man" into one group
            -Consolidate "Female" & "Woman" into one group
```{r}
table(df$gender, useNA = "always")
df$gender[df$gender == "Man"] <- "Male"
df$gender[df$gender == "Woman"] <- "Female"
```

     
     
        - 40.2% of race variable's observations (1067) are missing. let's see if the values in this variable has patterns.
Based on the contingency table below, 
            - all employees in Australia have no information about their race. 
            - 60/84 employees in Canada have no information about their race except 24 who are white.
            - 55/60 employees in China have no information about their race except 5 who are white.
            - 24/24 employees in Denmark have no information about their race.
            - 48/47 employees in Germany have no information about their race. 
            - 288/288 employees in India have no information about their race. 
            - 355/359 employees in the United Kingdom have no information about their race.
            - All employees in the United States have demographic information about race. 
Except for the United States, all the countries with missing information about race are largely ethnically homogeneous. Therefore, the company might not collect information about employee's race as the variance in race among employees might be too small. For example, about 90.2 percent of the population in Australia are white. Therefore, I only conduct an analysis about race for the United States only. 
```{r}
table(df$race, useNA = "always")

c_t <- table(df$race, df$country, useNA = "always")
c_t

```

        - 38.7% of hiring date variable's observations (1025) are missing. 
Based on the missmap graph as well as the contingency tables between hire year and another demographic predictor below (i.e., country ), the patterns of missing values for hiredate seem random.Research suggests that, when the pattern of missing values are random, omitting them does not introduce any bias. We have roughly 61% of the employees' hiredates that seem to be randomly caused based on the currently available data. Given that the population we want to understand is the entire employees, having 61% of the population's data is acceptable while it might be the best to have nearly 100% of data
          
```{r}
df_2 <- subset(df, select = c(hiredate, race))
library(Amelia)
missmap(df_2)

rm(df_2)
#the earliest & latest date for hiredate
min(df$hiredate, na.rm = TRUE) # 2012-01-10
max(df$hiredate, na.rm = TRUE) # 2022-12-06

#let's create a new variable named hireyear 
df$hireyear <- format(df$hiredate, "%Y")
table(df$hireyear, useNA = "always") #about 39% of employee hiredates are missing.
library(ggplot2)
ggplot(df, aes(x=hireyear)) + geom_bar()
ggplot(df, aes(x=hiredate)) + geom_histogram() #based on the hiredates, this company grew rapidly between 2020-2022


#let's create a contingency table for hireyear and country 
c_t <- table(df$hireyear, df$country, useNA = "always")
addmargins(c_t)
  ## Canada is missing 48/84 employees' hiredates
  ## China is missing 60/60 employees' hiredates
  ## United States is missing 917/1551 employees' hiredates
  ## In total, 1025/2651 employees' hire dates are missing. 
  ## I need to be careful about creating tenure groups for Canada, China, and the United States

#let's create a contingency table for hireyear and age
table(df$age, useNA = "always")
c_t <- table(df$hireyear, df$age, useNA = "always")
addmargins(c_t)
  ## 60/147 is missing for 18-24 old = 40.8%
  ## 469/1266 is missing for 25-34 old = 37%
  ## 1/1 is missing for 28 old 
  ## 296/795 is missing for 35-44 years old = 37%
  ## 1/1 is missing for 39 old
  ## 1/1 is missing for 42 old
  ## 141/301 is missing for 45-54 = 46%
  ## 43/78 is missing for 55-64 = 55%
  ## 9/54 is missing for 65+ = 16%
  ## 2 individuals have no age data.

#hireyear & manager status

table(df$manager_status, useNA = "always") # manager missing for hire_date = 265/654 = 41 %
c_t <- table(df$hireyear, df$manager_status, useNA = "always") # non-manager missing for hire_date = 760/1997 = 38%
addmargins(c_t)

#hireyear & gender

table(df$gender, useNA = "always") # female missing for hire_date = 310/816 = 38 %
c_t <- table(df$hireyear, df$gender, useNA = "always") # male missing for hire_date = 711/1826 = 39%
addmargins(c_t)

#hireyear & race
table(df$race, useNA = "always") 
c_t <- table(df$hireyear, df$race, useNA = "always") # no particular pattern of missing hiring dates based on race
addmargins(c_t)

```
  -Create a new variable called tenure by using hiredate.
      Substract hiredate from August 1st 2022, the date instructed by the technical assessment rubric: it's important to note that there are 55 employees who were hired on or after August 1st 2022. However, given that I am asked to analyze the data as of August 1st 2022, I omit these 55 observations to not introduce a bias in my data. 
```{r}
# the number of employees who were hired on or after August 1st 2022
participants_count <- sum(!is.na(df$hiredate) & df$hiredate >= as.Date("2022-08-01"))
participants_count
which(df$hiredate >= as.Date("2022-08-01"))


#let's create the cutpoint, which is 2022-08-01, to calculate tenure groups
cutpoint <- as.Date("2022-08-01")
#given that the average number of days in a month is 365/12 = 30.4166666667, 
tenure_days <- as.numeric(difftime(cutpoint, df$hiredate, units = "days"))
tenure_months <- as.numeric(difftime(cutpoint, df$hiredate, units = "days")/(365/12))

#create tenure_groups 
tenure_groups <- cut(tenure_months,
                      breaks = c(-Inf, 0.00001, 3, 6, 12, 24, 48, 72, 120, Inf),  # In months
                      labels = c("hired on or after 2022-08-01",  "Under 3 months", "3-6 months", "6-12 months", "1-2 years", "2-4 years", "4-6 years", "6-10 years", "10+ years"), right = FALSE) # right = FALSE to exclude the right side exact month

# Print the participants with hire date "2020-08-01"

table(tenure_groups, useNA = "always")
# Add tenure_group variable to data frame
df$tenure_group <- as.character(tenure_groups)

# Print the data frame with the new tenure_group variable
table(df$tenure_group, useNA = "always")

```

  -Create a new dataset by changing all the missing values to NA (I named this new dataset df_2)
  
```{r}

dfSummary(df)
df_2 <- df

df_2$ali_1[df_2$ali_1 == -1] <- NA 
df_2$ali_2[df_2$ali_2 == -1] <- NA
df_2$ali_3[df_2$ali_3 == -1] <- NA

df_2$col_1[df_2$col_1 == -1] <- NA 
df_2$col_2[df_2$col_2 == -1] <- NA 
df_2$col_3[df_2$col_3 == -1] <- NA 


df_2$eng_1[df_2$eng_1 == -1] <- NA 
df_2$eng_2[df_2$eng_2 == -1] <- NA
df_2$eng_3[df_2$eng_3 == -1] <- NA 
df_2$eng_4[df_2$eng_4 == -1] <- NA
df_2$eng_5[df_2$eng_5 == -1] <- NA

df_2$inc_1[df_2$inc_1 == -1] <- NA 
df_2$inc_2[df_2$inc_2 == -1] <- NA
df_2$inc_3[df_2$inc_3 == -1] <- NA
df_2$inc_4[df_2$inc_4 == -1] <- NA
df_2$inc_5[df_2$inc_5 == -1] <- NA 

df_2$lea_1[df_2$lea_1 == -1] <- NA
df_2$lea_2[df_2$lea_2 == -1] <- NA
df_2$lea_3[df_2$lea_3 == -1] <- NA
df_2$lea_4[df_2$lea_4 == -1] <- NA

df_2$age[df_2$age == "N/A"] <- NA
df_2$gender[df_2$gender == "Unknown"] <- NA

dfSummary(df_2)

```
  * Calculate the favorable scores for all questions and factors for Hooli Overall.
    - all questions' favorability scores below:
```{r}

dfSummary(df_2)
favorability_ali_1 <- sum(df_2$ali_1 %in% c(4,5))/sum(df_2$ali_1 %in% c(1:5))
favorability_ali_1
favorability_lea_4 <- sum(df_2$lea_4 %in% c(4,5))/sum(df_2$lea_4 %in% c(1:5))
favorability_lea_4

#let's create a loop function to calculate the favorability score for all questions:

function_favorability <- function(df) {
  favorability_score <- numeric(ncol(df))  # Include all columns
  column_names <- names(df)  # Get the column names
  
  for (i in 1:ncol(df)) {  # Start from column 1
    # Calculate the proportion
    favorability_score[i] <- sum(df[[i]] %in% c(4,5)) / sum(df[[i]] %in% c(1:5))
  }
  
  # Combine favorability scores and column names into a data frame
  result <- data.frame(column_name = column_names, favorability_score = favorability_score)
  
  return(result)
}

# Calculate favorability_score for columns 2 to 21
favorability_score <- function_favorability(df_2[, 2:21])

print(favorability_score)

```
      - Calculate factor scores for all factors 

    
     